{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from terminaltables import AsciiTable\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# Set color map\n",
    "cmap = plt.get_cmap('viridis')\n",
    "\n",
    "PATH_TO_DATA = '../data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.path.exists('%s/dataset' % PATH_TO_DATA), \\\n",
    "    \"Please execute the notebook 'build_feature_set.ipynb' before running this notebook.\"\n",
    "    \n",
    "# Load feature set and target values\n",
    "dataset = pd.read_pickle('%s/dataset' % PATH_TO_DATA)\n",
    "# Load corresponding articles\n",
    "articles = pd.read_pickle('%s/articles' % PATH_TO_DATA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Features: 26\n"
     ]
    }
   ],
   "source": [
    "# Extract list of feature names ('blog' is target column)\n",
    "feature_names = [col for col in dataset.columns if col != 'blog']\n",
    "\n",
    "# Turn features and target column into numpy arrays\n",
    "X = normalize(dataset[feature_names].values)\n",
    "y = dataset['blog'].values.flatten()\n",
    "\n",
    "print (\"Number of Features: %d\" % X.shape[1])\n",
    "# Total number of samples\n",
    "n = len(X)\n",
    "\n",
    "# Test set: 20% of total number of samples (randomly selected)\n",
    "test_idx = np.random.choice(range(n), size=int(0.2*n), replace=False)\n",
    "train_idx = np.isin(np.arange(n), test_idx, invert=True)\n",
    "\n",
    "# Split the training and test sets\n",
    "X_train, X_test, y_train, y_test = X[train_idx], X[test_idx], y[train_idx], y[test_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define classifier\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    " \n",
    "# Fit - Train\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make a prediction on test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Measure the performance of the model\n",
    "print (\"Test set accuracy: %.2f%%\\n\" %  float(100*accuracy_score(y_test, y_pred)))\n",
    "\n",
    "print (classification_report(y_test, y_pred, target_names=['News', 'Blog']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save prediction results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "results['id'] = articles.iloc[test_idx]['id']\n",
    "\n",
    "# Gold column consists of true media type\n",
    "results.loc[y_test == 0, 'gold'] = 'News'\n",
    "results.loc[y_test == 1, 'gold'] = 'Blog'\n",
    "\n",
    "# Prediction column consists of models predictions\n",
    "results.loc[y_pred == 0, 'prediction'] = 'News'\n",
    "results.loc[y_pred == 1, 'prediction'] = 'Blog'\n",
    "\n",
    "# Add column for whether the model was correct\n",
    "results.loc[y_test == y_pred, 'correct'] = 'yes'\n",
    "results.loc[y_test != y_pred, 'correnct'] = 'no'\n",
    "\n",
    "# Save to a csv-file\n",
    "results.to_csv('%s/results.csv' % PATH_TO_DATA, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Get confusion matrix by using sklearn method\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Scale values so that columns sum to 1\n",
    "cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Draw matrix\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "plt.title('Confusion Matrix')\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(cm_norm, interpolation='none', cmap=plt.cm.Blues, vmin=0, vmax=np.max(cm_norm))\n",
    "ax.xaxis.tick_bottom()\n",
    "# Add color bar which shows color - scale map\n",
    "fig.colorbar(cax)\n",
    "\n",
    "# Show number of samples and percentage of samples in each bucket\n",
    "thresh = cm_norm.max() / 2.\n",
    "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    plt.text(j, i, '%d (%.f%%)' % (cm[i,j], float(100*cm_norm[i,j])),\n",
    "             horizontalalignment='center',\n",
    "             color='white' if cm_norm[i, j] > thresh else 'black')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show labels\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Ground Truth')\n",
    "plt.xticks(np.arange(2), ('News', 'Blog'), rotation=45)\n",
    "plt.yticks(np.arange(2), ('News', 'Blog'))\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract feature importance from Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get feature importances from the RandomForestClassifier\n",
    "importances = clf.feature_importances_\n",
    "\n",
    "# Sort indices by the corresponding feature's importance\n",
    "idx = np.argsort(importances)[::-1]\n",
    "\n",
    "# Sort features and importances from highest to lowest importance\n",
    "sorted_feature_names = [feature_names[i] for i in idx]\n",
    "sorted_importances = [importances[i] for i in idx]\n",
    "\n",
    "# Get color spectrum\n",
    "colors = [cmap(i) for i in np.linspace(0, 1, len(idx))][::-1]\n",
    "\n",
    "# Plot features from highest to lowest feature importance\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.title(\"Feature importance\")\n",
    "plt.bar(range(len(idx)), sorted_importances, color=colors)\n",
    "plt.xticks(range(len(idx)), sorted_feature_names, rotation=45)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
